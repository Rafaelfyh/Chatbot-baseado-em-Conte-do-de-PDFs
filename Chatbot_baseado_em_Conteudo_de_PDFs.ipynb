{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zps82tc9Gfuh"
      },
      "outputs": [],
      "source": [
        "# Estrutura de arquivos\n",
        "# /inputs/texto.txt\n",
        "# /app.py\n",
        "# /README.md\n",
        "\n",
        "# Conteudo do app.py:\n",
        "\n",
        "import streamlit as st\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Carregando documento\n",
        "document_path = 'inputs/texto.txt'\n",
        "loader = TextLoader(document_path)\n",
        "\n",
        "# Dividindo texto\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "texts = text_splitter.split_documents(loader.load())\n",
        "\n",
        "# Gerando embeddings\n",
        "embeddings = HuggingFaceEmbeddings()\n",
        "vectorstore = FAISS.from_documents(texts, embeddings)\n",
        "\n",
        "# Carregando modelo\n",
        "llm = HuggingFaceHub(repo_id=\"google/flan-t5-base\", model_kwargs={\"temperature\":0, \"max_length\":512})\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever())\n",
        "\n",
        "# Streamlit Interface\n",
        "st.title(\"Chatbot Inteligente baseado em PDFs\")\n",
        "\n",
        "user_question = st.text_input(\"Faça sua pergunta sobre o conteúdo:\")\n",
        "\n",
        "if user_question:\n",
        "    response = qa_chain.run(user_question)\n",
        "    st.write(response)\n",
        "\n",
        "# Conteudo do README.md:\n",
        "\n",
        "# Chatbot baseado em Conteúdo de PDFs\n",
        "\n",
        "O projeto consiste em um chatbot que responde perguntas com base em documentos.\n",
        "\n",
        "## Tecnologias utilizadas\n",
        "- Python\n",
        "- LangChain\n",
        "- HuggingFace\n",
        "- FAISS\n",
        "- Streamlit\n",
        "\n",
        "## Como utilizar\n",
        "1. Suba seus textos no diretório `/inputs`\n",
        "2. Execute o `app.py`\n",
        "3. Interaja com o chatbot no navegador!\n",
        "\n",
        "## Desenvolvido por:\n",
        "**Rafael Queiroz**\n",
        "\n",
        "---\n",
        "\n",
        "# Conteudo do inputs/texto.txt"
      ]
    }
  ]
}